{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a7da76d8",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"335b20a7\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f30404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f4c811",
   "metadata": {},
   "source": [
    "Tensors are a specialised structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model's parameters.  \n",
    "***A Tensor is a numerical container of arbitrary dimensions, and it is the core data structure that PyTorch operates on.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7cf1c",
   "metadata": {},
   "source": [
    "## Tensor Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf79b0cf",
   "metadata": {},
   "source": [
    "\n",
    "**Directly from data**:  \n",
    "Tensors can be created directly from data. The data type is automatically inferred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec29fa",
   "metadata": {},
   "source": [
    "**From A Numpy Arrary**  \n",
    "Tensors can be created from Numpy arrays (and vice versa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3acb226",
   "metadata": {},
   "source": [
    "**From Another Tensor**  \n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66381c5",
   "metadata": {},
   "source": [
    "**with Random or Constant Values**  \n",
    "```shape``` is a tuple of tensor dimensions. In the functions below, it determines the dimensionally of the output tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6c7a23",
   "metadata": {},
   "source": [
    "## Tensor Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd6cfbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4991, 0.1349, 0.9505],\n",
      "        [0.4508, 0.6830, 0.3670]])\n",
      "Shape of Tensor: torch.Size([2, 3])\n",
      "Datatype of Tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(2,3)\n",
    "print(tensor)\n",
    "print(f\"Shape of Tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of Tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d9d451",
   "metadata": {},
   "source": [
    "Each of tensors can be run on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b19df1f",
   "metadata": {},
   "source": [
    "**Standard Numpy-like Indexing and Slicing**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f28ddfd",
   "metadata": {},
   "source": [
    "**Joinining Tensors**  \n",
    "You can use torch.cat to concatenate a sequence of tensors along a given dimensions.  \n",
    "*NOTE*\n",
    "1. The dimension you choose can have different lengths, because that is the one we are extending.\n",
    "2. All the other dimensions must be the same, otherwise, it is ike trying to stack Lego blocks of different sizes and they will not fit.  \n",
    "\n",
    "**torch.cat() VS torch.stack()**    \n",
    "|Operation|Result|Shape|Characteristics|\n",
    "|---------|------|-----|---------------|\n",
    "|torch.cat([a,b], dim = 0)|[[1,2,3],[4,5,6]]|(2,3)|Concatenates along rows -> stacked vertically|\n",
    "|torch.cat([a,b], dim=1)|[[1,2,3,4,5,6]]|(1,6)|Concatenates along columns -> stacjked horizontally|\n",
    "torch.stack([a,b].dim=0)|[[[1,2,3]],[[4,5,6]]]|(2,1,3)|Creates a new dimension at the front -> 3D tensor|\n",
    "|torch.stack([a,b], dim=1)|[[[1,2,3],[4,5,6]]]|(1,2,3)|Creates a new dimension in the middle -> 1 block of shape $(2 \\times 3)$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c5746",
   "metadata": {},
   "source": [
    "**Multiplying Tensors**  \n",
    "1. Element-wise Product: tensor1* tensor2, tensor1.mul(tensor2)\n",
    "2. Matrix multiplication: tensor11.matmul(tensor2), tensor1 @ tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8695275c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7, 10],\n",
      "        [ 7, 10]])\n",
      "tensor([[ 7, 10],\n",
      "        [ 7, 10]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "tensor1 = torch.tensor([[1,2], [1,2]])    \n",
    "tensor2 = torch.tensor([[1,2], [3,4]])\n",
    "# method 1\n",
    "tensor3 = tensor1 @ tensor2\n",
    "# method 2\n",
    "tensor4 = tensor1.matmul(tensor2)\n",
    "print(tensor3)\n",
    "print(tensor4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bccfa5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6919, 0.7100, 0.2123, 0.8367, 0.9037],\n",
      "        [0.2508, 0.6395, 0.2129, 0.0154, 0.5361],\n",
      "        [0.5801, 0.8836, 0.8760, 0.1594, 0.7700],\n",
      "        [0.7479, 0.5176, 0.7220, 0.5189, 0.3494],\n",
      "        [0.8948, 0.6106, 0.3327, 0.3970, 0.7814]])\n",
      "tensor([[5.6919, 5.7100, 5.2123, 5.8367, 5.9037],\n",
      "        [5.2508, 5.6395, 5.2129, 5.0154, 5.5361],\n",
      "        [5.5801, 5.8836, 5.8760, 5.1594, 5.7700],\n",
      "        [5.7479, 5.5176, 5.7220, 5.5189, 5.3494],\n",
      "        [5.8948, 5.6106, 5.3327, 5.3970, 5.7814]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(5,5)\n",
    "print(tensor)\n",
    "tensor_add5 = tensor.add_(5)\n",
    "print(tensor_add5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "759fc717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0101, 0.9939, 0.5913, 0.6275, 0.1166],\n",
       "        [0.1435, 0.4948, 0.6813, 0.6999, 0.7142],\n",
       "        [0.2320, 0.6258, 0.4327, 0.4303, 0.9632],\n",
       "        [0.8310, 0.0059, 0.4553, 0.0558, 0.1104],\n",
       "        [0.5218, 0.7494, 0.9381, 0.4372, 0.4053]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_new = torch.rand(5,5)\n",
    "tensor.copy_(tensor_new) # using copy_ to change the original tensor\n",
    "# the size of the tensor is the same as the original tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051d94b8",
   "metadata": {},
   "source": [
    "Tensors on the CPU can share their underlying memory locations, and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3fc9d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "tensor1 =  torch.ones(5)\n",
    "print(tensor1)\n",
    "n_array = tensor1.numpy()\n",
    "print(n_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "09e2e07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3. 3.]\n",
      "tensor([3., 3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "np.add(n_array, 1, out = n_array)\n",
    "print(n_array)\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8124660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n_array = np.ones(5)\n",
    "tensor1 = torch.from_numpy(n_array)\n",
    "print(n_array)\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f52bdf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 4. 4. 4. 4.]\n",
      "tensor([4., 4., 4., 4., 4.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tensor1.add_(2)\n",
    "print(n_array)\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad96ad",
   "metadata": {},
   "source": [
    "```torch.autograd``` is PyTorch's automatic differentiation engine that powers neural network training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab60e1",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a4c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3.6%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\junqi.wu/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "model = resnet18(weights = ResNet18_Weights.DEFAULT)\n",
    "data = torch.rand(1,3,64,64)\n",
    "labels = torch.rand(1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8bc7e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e777bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr = 1e-2, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d3cf76dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4197453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
